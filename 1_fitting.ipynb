{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import EarlyStopping\n",
    "from models import RegressionNet, RegressionDropout\n",
    "from generator import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建网络 创建model时候指定参数\n",
    "选择损失函数和优化器\n",
    "\"\"\"\n",
    "input_size = 400\n",
    "hidden_size = 128\n",
    "output_size = 5\n",
    "model = RegressionNet(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"提交到服务器前修改超参数\"\"\"\n",
    "sample_nums = 100000\n",
    "num_epochs = 400\n",
    "batch_size = 64\n",
    "patience =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "除非对数据集划分比例有要求否则无需更改\n",
    "\"\"\"\n",
    "x_data, y_data = generate_data(sample_nums)\n",
    "input_data = y_data\n",
    "output_data = x_data\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(input_data, output_data, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with cpu\n",
      "Epoch 1/30, Training Loss : 1007.0020, Validation Loss: 872.4782\n",
      "Test Loss:882.8263470703125\n",
      "Validation loss decreased (inf --> 872.478154).  Saving model ...\n",
      "Epoch 2/30, Training Loss : 925.1359, Validation Loss: 867.0909\n",
      "Test Loss:873.550333203125\n",
      "Validation loss decreased (872.478154 --> 867.090908).  Saving model ...\n",
      "Epoch 3/30, Training Loss : 897.1236, Validation Loss: 861.2138\n",
      "Test Loss:868.6149591796875\n",
      "Validation loss decreased (867.090908 --> 861.213847).  Saving model ...\n",
      "Epoch 4/30, Training Loss : 874.8774, Validation Loss: 859.8917\n",
      "Test Loss:866.471476529948\n",
      "Validation loss decreased (861.213847 --> 859.891747).  Saving model ...\n",
      "Epoch 5/30, Training Loss : 883.6454, Validation Loss: 852.4692\n",
      "Test Loss:858.6332717773438\n",
      "Validation loss decreased (859.891747 --> 852.469165).  Saving model ...\n",
      "Epoch 6/30, Training Loss : 859.1089, Validation Loss: 846.4865\n",
      "Test Loss:850.8920911783854\n",
      "Validation loss decreased (852.469165 --> 846.486452).  Saving model ...\n",
      "Epoch 7/30, Training Loss : 844.4702, Validation Loss: 839.0144\n",
      "Test Loss:843.6931945638021\n",
      "Validation loss decreased (846.486452 --> 839.014355).  Saving model ...\n",
      "Epoch 8/30, Training Loss : 845.4786, Validation Loss: 833.0778\n",
      "Test Loss:836.4587478190105\n",
      "Validation loss decreased (839.014355 --> 833.077801).  Saving model ...\n",
      "Epoch 9/30, Training Loss : 855.5618, Validation Loss: 824.8639\n",
      "Test Loss:827.7102780924479\n",
      "Validation loss decreased (833.077801 --> 824.863925).  Saving model ...\n",
      "Epoch 10/30, Training Loss : 834.2041, Validation Loss: 822.0190\n",
      "Test Loss:824.5678065755209\n",
      "Validation loss decreased (824.863925 --> 822.018997).  Saving model ...\n",
      "Epoch 11/30, Training Loss : 827.0103, Validation Loss: 816.4070\n",
      "Test Loss:818.7847262044271\n",
      "Validation loss decreased (822.018997 --> 816.407022).  Saving model ...\n",
      "Epoch 12/30, Training Loss : 831.3594, Validation Loss: 810.9409\n",
      "Test Loss:812.3352373372396\n",
      "Validation loss decreased (816.407022 --> 810.940885).  Saving model ...\n",
      "Epoch 13/30, Training Loss : 820.3135, Validation Loss: 805.2414\n",
      "Test Loss:806.5703844075521\n",
      "Validation loss decreased (810.940885 --> 805.241369).  Saving model ...\n",
      "Epoch 14/30, Training Loss : 814.5129, Validation Loss: 799.0665\n",
      "Test Loss:799.7993182942708\n",
      "Validation loss decreased (805.241369 --> 799.066478).  Saving model ...\n",
      "Epoch 15/30, Training Loss : 810.9339, Validation Loss: 792.4087\n",
      "Test Loss:792.8571343098959\n",
      "Validation loss decreased (799.066478 --> 792.408671).  Saving model ...\n",
      "Epoch 16/30, Training Loss : 802.1102, Validation Loss: 785.8734\n",
      "Test Loss:785.9130950195313\n",
      "Validation loss decreased (792.408671 --> 785.873439).  Saving model ...\n",
      "Epoch 17/30, Training Loss : 795.0901, Validation Loss: 778.3240\n",
      "Test Loss:778.1654377604167\n",
      "Validation loss decreased (785.873439 --> 778.323987).  Saving model ...\n",
      "Epoch 18/30, Training Loss : 797.8025, Validation Loss: 774.0056\n",
      "Test Loss:773.6113338867187\n",
      "Validation loss decreased (778.323987 --> 774.005636).  Saving model ...\n",
      "Epoch 19/30, Training Loss : 790.2981, Validation Loss: 771.2243\n",
      "Test Loss:770.9084274739583\n",
      "Validation loss decreased (774.005636 --> 771.224294).  Saving model ...\n",
      "Epoch 20/30, Training Loss : 791.2205, Validation Loss: 769.8827\n",
      "Test Loss:769.3369793945312\n",
      "Validation loss decreased (771.224294 --> 769.882715).  Saving model ...\n",
      "Epoch 21/30, Training Loss : 789.3842, Validation Loss: 769.0585\n",
      "Test Loss:768.5671521158854\n",
      "Validation loss decreased (769.882715 --> 769.058539).  Saving model ...\n",
      "Epoch 22/30, Training Loss : 784.3439, Validation Loss: 767.9233\n",
      "Test Loss:767.3838097330729\n",
      "Validation loss decreased (769.058539 --> 767.923285).  Saving model ...\n",
      "Epoch 23/30, Training Loss : 787.3102, Validation Loss: 767.2772\n",
      "Test Loss:766.8172479817708\n",
      "Validation loss decreased (767.923285 --> 767.277170).  Saving model ...\n",
      "Epoch 24/30, Training Loss : 781.6445, Validation Loss: 766.4596\n",
      "Test Loss:765.9200264648438\n",
      "Validation loss decreased (767.277170 --> 766.459647).  Saving model ...\n",
      "Epoch 25/30, Training Loss : 781.1696, Validation Loss: 765.9684\n",
      "Test Loss:765.4162126302083\n",
      "Validation loss decreased (766.459647 --> 765.968387).  Saving model ...\n",
      "Epoch 26/30, Training Loss : 780.0462, Validation Loss: 766.3409\n",
      "Test Loss:765.7989661132813\n",
      "EarlyStopping counter: 1 out of 2\n",
      "Epoch 27/30, Training Loss : 779.5162, Validation Loss: 765.7681\n",
      "Test Loss:765.1718818359375\n",
      "Validation loss decreased (765.968387 --> 765.768065).  Saving model ...\n",
      "Epoch 28/30, Training Loss : 781.6985, Validation Loss: 765.0327\n",
      "Test Loss:764.6522681640625\n",
      "Validation loss decreased (765.768065 --> 765.032674).  Saving model ...\n",
      "Epoch 29/30, Training Loss : 778.9037, Validation Loss: 764.4787\n",
      "Test Loss:764.2090556966145\n",
      "Validation loss decreased (765.032674 --> 764.478732).  Saving model ...\n",
      "Epoch 30/30, Training Loss : 777.4379, Validation Loss: 764.2224\n",
      "Test Loss:763.9098890950521\n",
      "Validation loss decreased (764.478732 --> 764.222399).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "除非网络对输入有特殊要求非则无需改动\n",
    "\"\"\"\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "stopped_epoch = None\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "print(f\"training with {device}\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss : {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    print(f'Test Loss:{test_loss}')\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch:{epoch}\")\n",
    "        stopped_epoch = epoch\n",
    "        break\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict()\n",
    "        best_model_epoch = epoch\n",
    "\n",
    "\n",
    "torch.save(best_model_state, f'save_best_model_epoch_{best_model_epoch}.pth')\n",
    "if early_stopping.early_stop:\n",
    "    torch.save(model.state_dict(), f'save_stopped_epoch_{stopped_epoch}.pth')\n",
    "else:\n",
    "    torch.save(model.state_dict(), f'save_last_model_{num_epochs}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
